{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8032150,"sourceType":"datasetVersion","datasetId":4734473},{"sourceId":27445,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":23121}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ntrain_y = pd.read_csv('/kaggle/input/alfa-scoring/train_target.csv')\n\n\ntrain_data = pd.read_parquet('/kaggle/input/alfa-scoring/train_data_0.pq')\nfor i in range(1, 12):\n    train_data = pd.concat([train_data, pd.read_parquet(f'/kaggle/input/alfa-scoring/train_data_{i}.pq')], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T15:32:06.166611Z","iopub.execute_input":"2024-04-08T15:32:06.167002Z","iopub.status.idle":"2024-04-08T15:32:53.924561Z","shell.execute_reply.started":"2024-04-08T15:32:06.166971Z","shell.execute_reply":"2024-04-08T15:32:53.923647Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Assuming your DataFrame is named 'df'\nfor col in train_data.columns:\n    if train_data[col].dtype == 'int64':\n        if train_data[col].max() < 255:\n            train_data[col] = train_data[col].astype('uint8')\n        elif train_data[col].max() < 65535:\n            train_data[col] = train_data[col].astype('uint16')\n        elif train_data[col].max() < 4294967295:\n            train_data[col] = train_data[col].astype('uint32')\n        else:\n            train_data[col] = train_data[col].astype('uint64')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T15:32:53.926754Z","iopub.execute_input":"2024-04-08T15:32:53.927594Z","iopub.status.idle":"2024-04-08T15:32:56.930711Z","shell.execute_reply.started":"2024-04-08T15:32:53.927555Z","shell.execute_reply":"2024-04-08T15:32:56.929782Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = train_data.sort_values(by=['id', 'rn'], ascending=[True, True]).groupby(\"id\").tail(5).reset_index().drop(\"index\", axis = 1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T15:33:30.257089Z","iopub.execute_input":"2024-04-08T15:33:30.257430Z","iopub.status.idle":"2024-04-08T15:33:42.742446Z","shell.execute_reply.started":"2024-04-08T15:33:30.257403Z","shell.execute_reply":"2024-04-08T15:33:42.741520Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  pre_fterm  \\\n0   0   6                 5                    0         11          8   \n1   0   7                 3                    9          1          2   \n2   0   8                 2                    9          2          3   \n3   0   9                 1                    9         11         13   \n4   0  10                 7                    9          2         10   \n\n   pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n0               12               11                       4   \n1               12               14                      15   \n2               12               14                      15   \n3               14                8                       2   \n4                8                8                      16   \n\n   pre_loans_next_pay_summ  ...  enc_paym_21  enc_paym_22  enc_paym_23  \\\n0                        2  ...            3            3            3   \n1                        5  ...            3            3            3   \n2                        5  ...            3            3            3   \n3                        5  ...            3            3            3   \n4                        4  ...            3            3            3   \n\n   enc_paym_24  enc_loans_account_holder_type  enc_loans_credit_status  \\\n0            4                              1                        2   \n1            4                              1                        3   \n2            4                              1                        3   \n3            4                              1                        2   \n4            4                              1                        2   \n\n   enc_loans_credit_type  enc_loans_account_cur  pclose_flag  fclose_flag  \n0                      3                      1            0            1  \n1                      4                      1            0            0  \n2                      4                      1            0            0  \n3                      4                      1            0            0  \n4                      4                      1            0            0  \n\n[5 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rn</th>\n      <th>pre_since_opened</th>\n      <th>pre_since_confirmed</th>\n      <th>pre_pterm</th>\n      <th>pre_fterm</th>\n      <th>pre_till_pclose</th>\n      <th>pre_till_fclose</th>\n      <th>pre_loans_credit_limit</th>\n      <th>pre_loans_next_pay_summ</th>\n      <th>...</th>\n      <th>enc_paym_21</th>\n      <th>enc_paym_22</th>\n      <th>enc_paym_23</th>\n      <th>enc_paym_24</th>\n      <th>enc_loans_account_holder_type</th>\n      <th>enc_loans_credit_status</th>\n      <th>enc_loans_credit_type</th>\n      <th>enc_loans_account_cur</th>\n      <th>pclose_flag</th>\n      <th>fclose_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>11</td>\n      <td>8</td>\n      <td>12</td>\n      <td>11</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>12</td>\n      <td>14</td>\n      <td>15</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2</td>\n      <td>3</td>\n      <td>12</td>\n      <td>14</td>\n      <td>15</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>9</td>\n      <td>11</td>\n      <td>13</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>10</td>\n      <td>7</td>\n      <td>9</td>\n      <td>2</td>\n      <td>10</td>\n      <td>8</td>\n      <td>8</td>\n      <td>16</td>\n      <td>4</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 61 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features = [\"pre_since_opened\", \"pre_since_confirmed\", \"pre_pterm\", \"pre_fterm\", \"pre_till_pclose\", \"pre_till_fclose\",\n            \"pre_loans_credit_limit\", \"pre_loans_next_pay_summ\", \"pre_loans_outstanding\", \"pre_loans_total_overdue\",\n            \"pre_loans_max_overdue_sum\", \"pre_loans_credit_cost_rate\",\n            \"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\",\n            \"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\",\n            \"pre_util\", \"pre_over2limit\", \"pre_maxover2limit\", \"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\",\n            \"enc_paym_0\", \"enc_paym_1\", \"enc_paym_2\", \"enc_paym_3\", \"enc_paym_4\", \"enc_paym_5\", \"enc_paym_6\", \"enc_paym_7\", \"enc_paym_8\",\n            \"enc_paym_9\", \"enc_paym_10\", \"enc_paym_11\", \"enc_paym_12\", \"enc_paym_13\", \"enc_paym_14\", \"enc_paym_15\", \"enc_paym_16\",\n            \"enc_paym_17\", \"enc_paym_18\", \"enc_paym_19\", \"enc_paym_20\", \"enc_paym_21\", \"enc_paym_22\", \"enc_paym_23\", \"enc_paym_24\",\n            \"enc_loans_account_holder_type\", \"enc_loans_credit_status\", \"enc_loans_credit_type\", \"enc_loans_account_cur\",\n            \"pclose_flag\", \"fclose_flag\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:45:56.885354Z","iopub.execute_input":"2024-04-08T08:45:56.885994Z","iopub.status.idle":"2024-04-08T08:45:56.892568Z","shell.execute_reply.started":"2024-04-08T08:45:56.885963Z","shell.execute_reply":"2024-04-08T08:45:56.891494Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport time\n\ntimestamp = time.time()\n\nsequences = []\nprint(\"Processing IDs:\")\ntotal_ids = train['id'].nunique()\nfor i, (id, group) in enumerate(train.groupby('id')):\n    sequences.append(torch.tensor(group.drop(columns=['id', 'rn']).values, dtype=torch.long))\n    # Manually print the progress\n    if i % 100000 == 0:  # update every 100000 iterations, you can change the frequency of updates here\n        print(f\"Processed {i}/{total_ids} IDs, time: {time.time()-timestamp}\")\nprint(f\"Processed {total_ids}/{total_ids} IDs, time: {time.time()-timestamp}\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-08T08:45:58.814543Z","iopub.execute_input":"2024-04-08T08:45:58.815136Z","iopub.status.idle":"2024-04-08T08:46:11.053993Z","shell.execute_reply.started":"2024-04-08T08:45:58.815106Z","shell.execute_reply":"2024-04-08T08:46:11.053036Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Processing IDs:\nProcessed 0/19260 IDs, time: 0.06031632423400879\nProcessed 19260/19260 IDs, time: 7.997386932373047\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch import nn, optim\nfrom tqdm import tqdm\n\npadded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:13.305741Z","iopub.execute_input":"2024-04-08T08:46:13.306262Z","iopub.status.idle":"2024-04-08T08:46:13.489293Z","shell.execute_reply.started":"2024-04-08T08:46:13.306231Z","shell.execute_reply":"2024-04-08T08:46:13.488500Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"labels = torch.tensor(train_y[:total_ids].drop(\"id\", axis=1).values, dtype=torch.float)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\npadded_sequences, labels = padded_sequences.to(device), labels.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:21.288159Z","iopub.execute_input":"2024-04-08T08:46:21.288537Z","iopub.status.idle":"2024-04-08T08:46:21.544600Z","shell.execute_reply.started":"2024-04-08T08:46:21.288507Z","shell.execute_reply":"2024-04-08T08:46:21.543630Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"padded_sequences = padded_sequences.to(torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:22.942977Z","iopub.execute_input":"2024-04-08T08:46:22.943332Z","iopub.status.idle":"2024-04-08T08:46:22.947617Z","shell.execute_reply.started":"2024-04-08T08:46:22.943302Z","shell.execute_reply":"2024-04-08T08:46:22.946646Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"padded_sequences.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:24.397166Z","iopub.execute_input":"2024-04-08T08:46:24.397543Z","iopub.status.idle":"2024-04-08T08:46:24.404646Z","shell.execute_reply.started":"2024-04-08T08:46:24.397514Z","shell.execute_reply":"2024-04-08T08:46:24.403657Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(torch.Size([19260, 7, 59]), torch.Size([19260, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass CreditScoringModel(nn.Module):\n    def __init__(self, num_embeddings, embedding_dims, hidden_size, num_layers, output_size):\n        super(CreditScoringModel, self).__init__()\n        \n        self.num_embeddings = num_embeddings\n        self.embedding_dims = embedding_dims\n        \n        # Эмбеддинги для категориальных признаков с дополнительным индексом для OOV\n        self.embeddings = nn.ModuleList([\n            nn.Embedding(num + 1, dim) for num, dim in zip(num_embeddings, embedding_dims)  # +1 для OOV токена\n        ])\n        \n        # Индекс OOV токена - максимальный индекс для каждого эмбеддинга\n        self.oov_indices = [num for num in num_embeddings]\n        \n        # Расчет общей размерности после объединения эмбеддингов\n        total_embedding_dim = sum(embedding_dims)\n        \n        # Инициализация слоя батч нормализации\n        self.batch_norm = nn.BatchNorm1d(total_embedding_dim)\n        \n        # GRU слой\n        self.gru = nn.GRU(total_embedding_dim, hidden_size, num_layers, batch_first=True, dropout=0.5)\n        \n        self.gru_dropout = nn.Dropout(0.2)\n        \n        # Выходной полносвязный слой\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        embeddings = []\n        for i, emb in enumerate(self.embeddings):\n            # Замена индексов, выходящих за пределы, на OOV индекс для соответствующего эмбеддинга\n            x_i = torch.where(x[:,:,i] < self.oov_indices[i], x[:,:,i], torch.full_like(x[:,:,i], self.oov_indices[i]))\n            embeddings.append(emb(x_i))\n        \n        x_embedded = torch.cat(embeddings, dim=2)\n        \n        # Применение батч нормализации. Поскольку nn.BatchNorm1d ожидает (batch, features),\n        # мы временно меняем размерность для батч нормализации, затем возвращаем обратно.\n        x_embedded = x_embedded.transpose(1, 2)\n        x_embedded = self.batch_norm(x_embedded)\n        x_embedded = x_embedded.transpose(1, 2)\n        \n        gru_out, _ = self.gru(x_embedded)\n        last_step_output = gru_out[:,-1,:]\n        last_step_output_dropout = self.gru_dropout(last_step_output)\n        out = self.fc(last_step_output_dropout)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:32.570990Z","iopub.execute_input":"2024-04-08T08:46:32.571808Z","iopub.status.idle":"2024-04-08T08:46:32.584085Z","shell.execute_reply.started":"2024-04-08T08:46:32.571777Z","shell.execute_reply":"2024-04-08T08:46:32.583128Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"unique_counts_per_feature = []\nfor i in range(padded_sequences.size(2)):  # Проходим по каждой колонке\n    column = padded_sequences[:,:, i]\n    # Исключаем паддинг\n    filtered_column = column[column != -1]\n    # Подсчитываем уникальные значения\n    unique_values = torch.unique(filtered_column)\n    unique_counts_per_feature.append(int(unique_values.max()))\n    #print(i, unique_values, int(unique_values[-1]))\n\nprint(\"Количество уникальных значений по признакам:\", unique_counts_per_feature) # Пример количества уникальных значений для каждого признака\n\n# Расчет размерностей эмбеддингов, понижая в 10 раз, но не меньше минимального порога (например, 2)\nembedding_dims = [max(2, (count + 1) // 2) for count in unique_counts_per_feature]\nnum_embeddings = [count + 1 for count in unique_counts_per_feature]\n\nprint(\"Количество эмбеддингов:\", num_embeddings)\nprint(\"Размерности эмбеддингов:\", embedding_dims)    \n    \nhidden_size = 128\nnum_layers = 2\noutput_size = 1  # Для бинарной классификации\n\n# Инициализация модели\nmodel = CreditScoringModel(num_embeddings, embedding_dims, hidden_size, num_layers, output_size)\n\n# Перенос модели на GPU, если доступно\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Определение функции потерь и оптимизатора\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:34.644271Z","iopub.execute_input":"2024-04-08T08:46:34.645024Z","iopub.status.idle":"2024-04-08T08:46:37.690638Z","shell.execute_reply.started":"2024-04-08T08:46:34.644993Z","shell.execute_reply":"2024-04-08T08:46:37.689818Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Количество уникальных значений по признакам: [19, 17, 17, 16, 16, 15, 19, 6, 5, 0, 3, 13, 16, 18, 8, 4, 14, 1, 1, 1, 1, 1, 19, 19, 19, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 6, 6, 5, 3, 1, 1]\nКоличество эмбеддингов: [20, 18, 18, 17, 17, 16, 20, 7, 6, 1, 4, 14, 17, 19, 9, 5, 15, 2, 2, 2, 2, 2, 20, 20, 20, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 7, 7, 6, 4, 2, 2]\nРазмерности эмбеддингов: [10, 9, 9, 8, 8, 8, 10, 3, 3, 2, 2, 7, 8, 9, 4, 2, 7, 2, 2, 2, 2, 2, 10, 10, 10, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\n# Преобразование данных в тензоры PyTorch\nsequences_tensor = torch.tensor(padded_sequences, dtype=torch.long)\nlabels_tensor = torch.tensor(labels, dtype=torch.float)\n\n# Создание датасета\ndataset = TensorDataset(sequences_tensor, labels_tensor)\n\n# DataLoader для эффективного разбиения данных на батчи\nbatch_size = 64  # Вы можете адаптировать размер батча к возможностям вашего оборудования\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:37.692178Z","iopub.execute_input":"2024-04-08T08:46:37.692622Z","iopub.status.idle":"2024-04-08T08:46:37.699563Z","shell.execute_reply.started":"2024-04-08T08:46:37.692595Z","shell.execute_reply":"2024-04-08T08:46:37.698652Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1261106096.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  sequences_tensor = torch.tensor(padded_sequences, dtype=torch.long)\n/tmp/ipykernel_34/1261106096.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels_tensor = torch.tensor(labels, dtype=torch.float)\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, emb in enumerate(model.embeddings):\n    max_index = emb.num_embeddings - 1\n    if sequences_tensor[:,:,i].min() < 0 or sequences_tensor[:,:,i].max() > max_index:\n        print(f\"Ошибка в индексах для слоя эмбеддинга {i}: min {sequences_tensor[:,:,i].min()}, max {sequences_tensor[:,:,i].max()}, должно быть между 0 и {max_index}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:39.274989Z","iopub.execute_input":"2024-04-08T08:46:39.275347Z","iopub.status.idle":"2024-04-08T08:46:39.347404Z","shell.execute_reply.started":"2024-04-08T08:46:39.275319Z","shell.execute_reply":"2024-04-08T08:46:39.346577Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass EarlyStopping:\n    \"\"\"Ранняя остановка обучения модели, если валидационная потеря не уменьшается.\"\"\"\n    def __init__(self, patience=5, verbose=False, delta=0):\n        \"\"\"\n        Args:\n            patience (int): Количество эпох без улучшения после которых обучение будет остановлено.\n            verbose (bool): Выводить сообщения при ранней остановке.\n            delta (float): Минимальное изменение для расчета как улучшение.\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = float('inf')\n        self.delta = delta\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Сохраняет модель при улучшении валидационной потери.\"\"\"\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), 'checkpoint_model.pth')\n        self.val_loss_min = val_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:41.008962Z","iopub.execute_input":"2024-04-08T08:46:41.009739Z","iopub.status.idle":"2024-04-08T08:46:41.019585Z","shell.execute_reply.started":"2024-04-08T08:46:41.009707Z","shell.execute_reply":"2024-04-08T08:46:41.018579Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(patience=2, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:42.110908Z","iopub.execute_input":"2024-04-08T08:46:42.111741Z","iopub.status.idle":"2024-04-08T08:46:42.115752Z","shell.execute_reply.started":"2024-04-08T08:46:42.111702Z","shell.execute_reply":"2024-04-08T08:46:42.114806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nn_epochs = 30  # Указываем общее количество эпох\ndef training(n_epochs, model):\n    for epoch in range(n_epochs):\n        model.train()\n        total_loss = 0.0\n        print(f\"Start Epoch: {epoch+1}\")\n\n        # Обертываем dataloader в tqdm для визуализации прогресса\n        for sequences_batch, labels_batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n            sequences_batch, labels_batch = sequences_batch.to(device), labels_batch.to(device)\n            optimizer.zero_grad()\n            outputs = model(sequences_batch)\n            loss = criterion(outputs.squeeze(-1), labels_batch.squeeze(-1))\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(dataloader)\n        print(f'Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}')\n        \n        early_stopping(avg_loss, model)\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:43.927967Z","iopub.execute_input":"2024-04-08T08:46:43.928782Z","iopub.status.idle":"2024-04-08T08:46:43.936295Z","shell.execute_reply.started":"2024-04-08T08:46:43.928751Z","shell.execute_reply":"2024-04-08T08:46:43.935365Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"training(n_epochs, model)\ntorch.save(model.state_dict(), 'model_10.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:46:45.161820Z","iopub.execute_input":"2024-04-08T08:46:45.162164Z","iopub.status.idle":"2024-04-08T08:47:37.050247Z","shell.execute_reply.started":"2024-04-08T08:46:45.162138Z","shell.execute_reply":"2024-04-08T08:47:37.049233Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Start Epoch: 1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 301/301 [00:06<00:00, 47.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 0.1403\nValidation loss decreased (inf --> 0.140260).  Saving model ...\nStart Epoch: 2\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 301/301 [00:04<00:00, 60.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Loss: 0.1236\nValidation loss decreased (0.140260 --> 0.123605).  Saving model ...\nStart Epoch: 3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 301/301 [00:05<00:00, 59.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Loss: 0.1178\nValidation loss decreased (0.123605 --> 0.117809).  Saving model ...\nStart Epoch: 4\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 301/301 [00:04<00:00, 60.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Loss: 0.1095\nValidation loss decreased (0.117809 --> 0.109539).  Saving model ...\nStart Epoch: 5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 301/301 [00:05<00:00, 57.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Loss: 0.0963\nValidation loss decreased (0.109539 --> 0.096279).  Saving model ...\nStart Epoch: 6\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 301/301 [00:05<00:00, 59.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Loss: 0.0797\nValidation loss decreased (0.096279 --> 0.079733).  Saving model ...\nStart Epoch: 7\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 301/301 [00:04<00:00, 60.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Loss: 0.0564\nValidation loss decreased (0.079733 --> 0.056429).  Saving model ...\nStart Epoch: 8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 301/301 [00:05<00:00, 60.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Loss: 0.0414\nValidation loss decreased (0.056429 --> 0.041410).  Saving model ...\nStart Epoch: 9\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 301/301 [00:05<00:00, 59.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Loss: 0.0348\nValidation loss decreased (0.041410 --> 0.034806).  Saving model ...\nStart Epoch: 10\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 301/301 [00:05<00:00, 59.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Loss: 0.0250\nValidation loss decreased (0.034806 --> 0.024986).  Saving model ...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EVAL","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ntest_y = pd.read_csv('/kaggle/input/alfa-scoring/test_target.csv')\ntest1 = pd.read_parquet('/kaggle/input/alfa-scoring/test_data_0.pq')\ntest2 = pd.read_parquet('/kaggle/input/alfa-scoring/test_data_1.pq')\ntest_data = pd.concat([test1, test2], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:30:06.662016Z","iopub.execute_input":"2024-04-08T05:30:06.662276Z","iopub.status.idle":"2024-04-08T05:30:11.409333Z","shell.execute_reply.started":"2024-04-08T05:30:06.662251Z","shell.execute_reply":"2024-04-08T05:30:11.408367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch import nn, optim\nfrom tqdm import tqdm\nimport time\nimport torch\n\n# Assuming your DataFrame is named 'df'\nfor col in test_data.columns:\n    if test_data[col].dtype == 'int64':\n        if test_data[col].max() < 255:\n            test_data[col] = test_data[col].astype('uint8')\n        elif test_data[col].max() < 65535:\n            test_data[col] = test_data[col].astype('uint16')\n        elif test_data[col].max() < 4294967295:\n            test_data[col] = test_data[col].astype('uint32')\n        else:\n            test_data[col] = test_data[col].astype('uint64')\n\ntest = test_data.sort_values(by=['id', 'rn'], ascending=[True, True]).groupby(\"id\").tail(5).reset_index().drop(\"index\", axis = 1)\n\nsequences0 = []\nprint(\"Processing IDs:\")\ntotal_ids0 = test['id'].nunique()\ntimestamp = time.time()\nfor i, (id, group) in enumerate(test.groupby('id')):\n    sequences0.append(torch.tensor(group.drop(columns=['id', 'rn']).values, dtype=torch.long))\n    # Manually print the progress\n    if i % 10000 == 0:  # update every 100 iterations, you can change the frequency of updates here\n        print(f\"Processed {i}/{total_ids0} IDs time:{time.time()-timestamp}\")\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:31:33.853126Z","iopub.execute_input":"2024-04-08T05:31:33.853536Z","iopub.status.idle":"2024-04-08T05:35:09.674621Z","shell.execute_reply.started":"2024-04-08T05:31:33.853504Z","shell.execute_reply":"2024-04-08T05:35:09.673798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padded_sequences0 = pad_sequence(sequences0, batch_first=True, padding_value=0)\nlabels0 = torch.tensor(test_y[:total_ids0].drop(\"id\", axis=1).values, dtype=torch.float)\ndevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n\npadded_sequences0, labels0 = padded_sequences0.to(device), labels0.to(device)\npadded_sequences0 = padded_sequences0.to(torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:35:14.623269Z","iopub.execute_input":"2024-04-08T05:35:14.623634Z","iopub.status.idle":"2024-04-08T05:35:18.716980Z","shell.execute_reply.started":"2024-04-08T05:35:14.623606Z","shell.execute_reply":"2024-04-08T05:35:18.716191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nif 'model' not in locals():\n    unique_counts_per_feature = []\n    for i in range(padded_sequences0.size(2)):  # Проходим по каждой колонке\n        column = padded_sequences0[:,:, i]\n        # Исключаем паддинг\n        filtered_column = column[column != -1]\n        # Подсчитываем уникальные значения\n        unique_values = torch.unique(filtered_column)\n        unique_counts_per_feature.append(int(unique_values.max()))\n        #print(i, unique_values, int(unique_values[-1]))\n\n    print(\"Количество уникальных значений по признакам:\", unique_counts_per_feature) # Пример количества уникальных значений для каждого признака\n\n    # Расчет размерностей эмбеддингов, понижая в 10 раз, но не меньше минимального порога (например, 2)\n    embedding_dims = [max(2, (count + 1) // 2) for count in unique_counts_per_feature]\n    num_embeddings = [count + 1 for count in unique_counts_per_feature]\n\n    num_embeddings[9], embedding_dims[9] = 2, 2\n    num_embeddings[15], embedding_dims[15] = 5, 2\n    num_embeddings[56], embedding_dims[56] = 4, 2\n\n    print(\"Количество эмбеддингов:\", num_embeddings)\n    print(\"Размерности эмбеддингов:\", embedding_dims)    \n    \n    hidden_size = 128\n    num_layers = 2\n    output_size = 1  # Для бинарной классификации\n\n# Инициализация модели\n    model = CreditScoringModel(num_embeddings, embedding_dims, hidden_size, num_layers, output_size)\n\n#print(model.embeddings)\n\n    model.load_state_dict(torch.load(\"/kaggle/input/alfa_gru/pytorch/10ep1/1/model_10.pth\"), strict=False)\n#model.load_state_dict(torch.load(\"/kaggle/working/model_10.pth\"))\n\nelse:\n    print(\"Model already here\")\n# Перенос модели на GPU, если доступно\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:57:29.501945Z","iopub.execute_input":"2024-04-08T05:57:29.502355Z","iopub.status.idle":"2024-04-08T05:57:29.516647Z","shell.execute_reply.started":"2024-04-08T05:57:29.502323Z","shell.execute_reply":"2024-04-08T05:57:29.515555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nsequences_tensor0 = torch.tensor(padded_sequences0, dtype=torch.long)\nlabels_tensor0 = torch.tensor(labels0, dtype=torch.float)\n\ntest_labels_dataset = TensorDataset(sequences_tensor0, labels_tensor0)\ntest_labels_dataloader = DataLoader(test_labels_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:46:42.318139Z","iopub.execute_input":"2024-04-08T05:46:42.318490Z","iopub.status.idle":"2024-04-08T05:46:42.325226Z","shell.execute_reply.started":"2024-04-08T05:46:42.318462Z","shell.execute_reply":"2024-04-08T05:46:42.324276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, emb in enumerate(model.embeddings):\n    max_index = emb.num_embeddings - 1\n    if sequences_tensor0[:,:,i].min() < 0 or sequences_tensor0[:,:,i].max() > max_index:\n        print(f\"Ошибка в индексах для слоя эмбеддинга {i}: min {sequences_tensor0[:,:,i].min()}, max {sequences_tensor0[:,:,i].max()}, должно быть между 0 и {max_index}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:46:44.379497Z","iopub.execute_input":"2024-04-08T05:46:44.379888Z","iopub.status.idle":"2024-04-08T05:46:44.602040Z","shell.execute_reply.started":"2024-04-08T05:46:44.379857Z","shell.execute_reply":"2024-04-08T05:46:44.601266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval(model):\n# Список для хранения предсказаний и истинных меток\n    predictions = []\n\n    model.eval()  # Переводим модель в режим оценки\n\n    with torch.no_grad():  # Отключаем вычисление градиентов\n        for sequences_batch, labels_batch in test_labels_dataloader:\n            sequences_batch = sequences_batch.to(device)\n            labels_batch = labels_batch.to(device)\n        \n            outputs = model(sequences_batch)\n            predicted_probs = torch.sigmoid(outputs.squeeze(-1)).cpu().numpy()  # Получение вероятностей\n            predictions.extend(predicted_probs)\n        return predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:46:46.497394Z","iopub.execute_input":"2024-04-08T05:46:46.498216Z","iopub.status.idle":"2024-04-08T05:46:46.505668Z","shell.execute_reply.started":"2024-04-08T05:46:46.498178Z","shell.execute_reply":"2024-04-08T05:46:46.504721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = eval(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:46:54.100673Z","iopub.execute_input":"2024-04-08T05:46:54.101096Z","iopub.status.idle":"2024-04-08T05:48:05.926702Z","shell.execute_reply.started":"2024-04-08T05:46:54.101065Z","shell.execute_reply":"2024-04-08T05:48:05.925891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.array(pred)\n\nsubmission = pd.DataFrame({\n    \"id\": test_y[:total_ids0][\"id\"],  # Убедитесь, что этот массив содержит ID тестовых данных в правильном порядке\n    \"score\": predictions\n})\nsubmission.to_csv(\"sample_submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T05:48:10.912723Z","iopub.execute_input":"2024-04-08T05:48:10.913548Z","iopub.status.idle":"2024-04-08T05:48:12.061088Z","shell.execute_reply.started":"2024-04-08T05:48:10.913518Z","shell.execute_reply":"2024-04-08T05:48:12.060280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}